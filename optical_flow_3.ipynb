{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "video_data_path = 'HMDB51/video_data'\n",
    "optical_flow_path = 'HMDB51/opt_flows'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_flow_components(flow):\n",
    "    horz = cv2.normalize(flow[...,0], None, 0, 255, cv2.NORM_MINMAX)     \n",
    "    vert = cv2.normalize(flow[...,1], None, 0, 255, cv2.NORM_MINMAX)\n",
    "    horz = horz.astype('uint8')\n",
    "    vert = vert.astype('uint8')\n",
    "\n",
    "\n",
    "    return horz, vert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hsv(flow, mask):\n",
    "    \n",
    "\n",
    "    # Computes the magnitude and angle of the 2D vectors \n",
    "    magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1]) \n",
    "      \n",
    "    # Sets image hue according to the optical flow  \n",
    "    # direction \n",
    "    mask[..., 0] = angle * 180 / np.pi / 2\n",
    "      \n",
    "    # Sets image value according to the optical flow \n",
    "    # magnitude (normalized) \n",
    "    mask[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX) \n",
    "      \n",
    "    # Converts HSV to RGB (BGR) color representation \n",
    "    rgb = cv2.cvtColor(mask, cv2.COLOR_HSV2BGR) \n",
    "    return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_optical_flow(video_path, output_dir):\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Count total frames\n",
    "    video_frames_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_step = max(video_frames_count // 16, 1)  \n",
    "              \n",
    "    # Reset video capture to first frame\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    ret, prev_frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "      print(f\"Video {video_path} can't be read\")\n",
    "      return  # Exit if the video can't be read\n",
    "    \n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_count = 0\n",
    "    opt_flow_count = 0\n",
    "    \n",
    "    mask = np.zeros_like(prev_frame) \n",
    "    \n",
    "    # Sets image saturation to maximum \n",
    "    mask[..., 1] = 255\n",
    "    \n",
    "    while True:\n",
    "        ret, next_frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Exit loop if no more frames are available\n",
    "\n",
    "        if frame_count % frame_step == 0:\n",
    "            next_gray = cv2.cvtColor(next_frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            '''\n",
    "            - pyr_scale (0.5): Scaling factor for constructing the image pyramid. \n",
    "              0.5 indicates that each layer of the pyramid is half the size of the previous layer.\n",
    "            - levels (3): The number of pyramid layers.\n",
    "            - winsize (15): The averaging window size. The size of the window used to smooth the optical flow. \n",
    "            - iterations (3): The number of iterations the algorithm will use at each pyramid level.\n",
    "            - poly_n (5): The size of the pixel neighborhood used to find polynomial expansion in each pixel.  \n",
    "            - poly_sigma (1.2): Standard deviation of the Gaussian that is used to smooth derivatives for the polynomial expansion.\n",
    "            - flags (0): Commonly used value is 0.\n",
    "            '''\n",
    "            flow = cv2.calcOpticalFlowFarneback(prev_gray, next_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "                                    \n",
    "            ### CASE OF VERTICAL AND HORIZONTAL ###\n",
    "            # flow_filename_horizontal = os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(video_path))[0]}_opt_flow_{opt_flow_count}_hori.jpeg\")\n",
    "            # flow_filename_vertical = os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(video_path))[0]}_opt_flow_{opt_flow_count}_vert.jpeg\")\n",
    "            \n",
    "            # flow_image_horizontal, flow_image_vertical = draw_flow_components(flow)\n",
    "                        \n",
    "            # cv2.imwrite(flow_filename_horizontal, flow_image_horizontal)\n",
    "            # cv2.imwrite(flow_filename_vertical, flow_image_vertical)\n",
    "            \n",
    "            ### CASE OF COLLORFUL ###\n",
    "            flow_filename = os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(video_path))[0]}_opt_flow_{opt_flow_count}.jpeg\")\n",
    "            flow_image = draw_hsv(flow, mask)\n",
    "            cv2.imwrite(flow_filename, flow_image)\n",
    "            \n",
    "            opt_flow_count += 1\n",
    "    \n",
    "        frame_count += 1\n",
    "        \n",
    "    return opt_flow_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [35], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     14\u001b[0m video_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(action_class_path, video)\n\u001b[1;32m---> 16\u001b[0m opt_frames_count \u001b[38;5;241m=\u001b[39m \u001b[43msave_optical_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_class_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_frames_count \u001b[38;5;241m<\u001b[39m min_opt_frames:\n\u001b[0;32m     19\u001b[0m     min_opt_frames \u001b[38;5;241m=\u001b[39m opt_frames_count\n",
      "Cell \u001b[1;32mIn [32], line 44\u001b[0m, in \u001b[0;36msave_optical_flow\u001b[1;34m(video_path, output_dir)\u001b[0m\n\u001b[0;32m     32\u001b[0m next_gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(next_frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m- pyr_scale (0.5): Scaling factor for constructing the image pyramid. \u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m  0.5 indicates that each layer of the pyramid is half the size of the previous layer.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m- flags (0): Commonly used value is 0.\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m flow \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalcOpticalFlowFarneback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m### CASE OF VERTICAL AND HORIZONTAL ###\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# flow_filename_horizontal = os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(video_path))[0]}_opt_flow_{opt_flow_count}_hori.jpeg\")\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# flow_filename_vertical = os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(video_path))[0]}_opt_flow_{opt_flow_count}_vert.jpeg\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m \n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m### CASE OF COLLORFUL ###\u001b[39;00m\n\u001b[0;32m     56\u001b[0m flow_filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(video_path))[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_opt_flow_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopt_flow_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "files_per_action = []\n",
    "min_opt_frames = 25\n",
    "\n",
    "for action_class in os.listdir(video_data_path):\n",
    "    counter = 0\n",
    "    action_class_path = os.path.join(video_data_path, action_class)\n",
    "    output_class_path = os.path.join(optical_flow_path, action_class)\n",
    "\n",
    "    if not os.path.exists(output_class_path):\n",
    "        os.makedirs(output_class_path)\n",
    "\n",
    "    for video in os.listdir(action_class_path):\n",
    "        counter += 1\n",
    "        video_path = os.path.join(action_class_path, video)\n",
    "        \n",
    "        opt_frames_count = save_optical_flow(video_path, output_class_path)\n",
    "        \n",
    "        if opt_frames_count < min_opt_frames:\n",
    "            min_opt_frames = opt_frames_count\n",
    "        \n",
    "    files_per_action.append(counter)\n",
    "    \n",
    "    \n",
    "print(files_per_action)\n",
    "print(\"Min number of frames:\", min_opt_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def process_action_class(action_class_path):\n",
    "    # Dictionary to hold frame count for each video\n",
    "    video_frame_counts = {}\n",
    "\n",
    "    # Identify and count frames for each video\n",
    "    for file_name in os.listdir(action_class_path):\n",
    "        match = re.match(r\"(.+)_opt_flow_(\\d+)\\.jpeg\", file_name)\n",
    "        if match:\n",
    "            video_name, frame_num = match.groups()\n",
    "            frame_num = int(frame_num)\n",
    "\n",
    "            if video_name not in video_frame_counts:\n",
    "                video_frame_counts[video_name] = []\n",
    "\n",
    "            video_frame_counts[video_name].append((frame_num, file_name))\n",
    "\n",
    "    # Remove excess frames\n",
    "    for video_name, frames in video_frame_counts.items():\n",
    "        if len(frames) > min_opt_frames:\n",
    "            # Sort frames by frame number and keep the first 'min_opt_frames'\n",
    "            frames_to_remove = sorted(frames, key=lambda x: x[0])[min_opt_frames:]\n",
    "            for _, frame_name in frames_to_remove:\n",
    "                frame_path = os.path.join(action_class_path, frame_name)\n",
    "                os.remove(frame_path)  # Delete the frame\n",
    "\n",
    "\n",
    "\n",
    "for action_class in os.listdir(optical_flow_path):\n",
    "    class_path = os.path.join(optical_flow_path, action_class)\n",
    "    if os.path.isdir(class_path):\n",
    "        process_action_class(class_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
